{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0      ID  air_time1  disp_index1  gmrt_in_air1  gmrt_on_paper1  \\\n",
      "0             0    id_1       5160     0.000013    120.804174       86.853334   \n",
      "1             1    id_2      51980     0.000016    115.318238       83.448681   \n",
      "2             2    id_3       2600     0.000010    229.933997      172.761858   \n",
      "3             3    id_4       2130     0.000010    369.403342      183.193104   \n",
      "4             4    id_5       2310     0.000007    257.997131      111.275889   \n",
      "..          ...     ...        ...          ...           ...             ...   \n",
      "169         169  id_170       2930     0.000010    241.736477      176.115957   \n",
      "170         170  id_171       2140     0.000009    274.728964      234.495802   \n",
      "171         171  id_172       3830     0.000008    151.536989      171.104693   \n",
      "172         172  id_173       1760     0.000008    289.518195      196.411138   \n",
      "173         173  id_174       2875     0.000008    235.769350      178.208024   \n",
      "\n",
      "     max_x_extension1  max_y_extension1  mean_acc_in_air1  mean_acc_on_paper1  \\\n",
      "0                 957              6601          0.361800            0.217459   \n",
      "1                1694              6998          0.272513            0.144880   \n",
      "2                2333              5802          0.387020            0.181342   \n",
      "3                1756              8159          0.556879            0.164502   \n",
      "4                 987              4732          0.266077            0.145104   \n",
      "..                ...               ...               ...                 ...   \n",
      "169              1839              6439          0.253347            0.174663   \n",
      "170              2053              8487          0.225537            0.174920   \n",
      "171              1287              7352          0.165480            0.161058   \n",
      "172              1674              6946          0.518937            0.202613   \n",
      "173              1838              6560          0.567311            0.147818   \n",
      "\n",
      "     ...  mean_jerk_in_air25  mean_jerk_on_paper25  mean_speed_in_air25  \\\n",
      "0    ...            0.141434              0.024471             5.596487   \n",
      "1    ...            0.049663              0.018368             1.665973   \n",
      "2    ...            0.178194              0.017174             4.000781   \n",
      "3    ...            0.113905              0.019860             4.206746   \n",
      "4    ...            0.121782              0.020872             3.319036   \n",
      "..   ...                 ...                   ...                  ...   \n",
      "169  ...            0.119152              0.020909             4.508709   \n",
      "170  ...            0.174495              0.017640             4.685573   \n",
      "171  ...            0.114472              0.017194             3.493815   \n",
      "172  ...            0.114472              0.017194             3.493815   \n",
      "173  ...            0.114472              0.017194             3.493815   \n",
      "\n",
      "     mean_speed_on_paper25  num_of_pendown25  paper_time25  pressure_mean25  \\\n",
      "0                 3.184589                71         40120      1749.278166   \n",
      "1                 0.950249               129        126700      1504.768272   \n",
      "2                 2.392521                74         45480      1431.443492   \n",
      "3                 1.613522               123         67945      1465.843329   \n",
      "4                 1.680629                92         37285      1841.702561   \n",
      "..                     ...               ...           ...              ...   \n",
      "169               2.233198                96         44545      1798.923336   \n",
      "170               2.806888                84         37560      1725.619941   \n",
      "171               2.510601                88         51675      1915.573488   \n",
      "172               2.510601                88         51675      1915.573488   \n",
      "173               2.510601                88         51675      1915.573488   \n",
      "\n",
      "     pressure_var25  total_time25  class  \n",
      "0       296102.7676        144605      1  \n",
      "1       278744.2850        298640      1  \n",
      "2       144411.7055         79025      1  \n",
      "3       230184.7154        181220      1  \n",
      "4       158290.0255         72575      1  \n",
      "..              ...           ...    ...  \n",
      "169     247448.3108         80335      0  \n",
      "170     160664.6464        345835      0  \n",
      "171     128727.1241         83445      0  \n",
      "172     128727.1241         83445      0  \n",
      "173     128727.1241         83445      0  \n",
      "\n",
      "[174 rows x 453 columns]\n"
     ]
    }
   ],
   "source": [
    "darwin_df = pd.read_csv('processed_df.csv')\n",
    "print(darwin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8571428571428571\n",
      "Training Accuracy: 0.9568345323741008\n",
      "Confusion Matrix:\n",
      " [[15  1]\n",
      " [ 4 15]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        16\n",
      "           1       0.94      0.79      0.86        19\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.86      0.86      0.86        35\n",
      "weighted avg       0.87      0.86      0.86        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'ID' column as it's not needed for the prediction\n",
    "df = darwin_df.drop(columns=['ID'])\n",
    "\n",
    "# Step 2: We are trying to predict the value of 'Class'\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Normalize the features\n",
    "normalizer = Normalizer()\n",
    "X_normalized = normalizer.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=13)\n",
    "\n",
    "# Step 4: Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(model.score(X_test,y_test)))\n",
    "print(\"Training Accuracy: \" + str(model.score(X_train,y_train)))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Model Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.342026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     True  Predicted  Model Probability\n",
       "170     0          0           0.342026\n",
       "7       1          0           0.338117\n",
       "104     0          0           0.385061\n",
       "93      0          0           0.234167\n",
       "10      1          1           0.909788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Compare True results vs Prediction results\n",
    "comparison_df = pd.DataFrame({'True': y_test, 'Predicted': y_pred, 'Model Probability': y_pred_proba})\n",
    "comparison_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
